#!/usr/bin/env python3
"""
ğŸš€ IMPLEMENTAÃ‡ÃƒO FASE 1 - FONTES CRÃTICAS CBIC
==============================================

Implementa as fontes mais crÃ­ticas do CBIC para criar uma base sÃ³lida
do sistema de BI antes da expansÃ£o completa.

FONTES FASE 1 (CRÃTICAS):
1. CUB Global Oneroso (mensal)
2. CUB Global por UF (mensal) 
3. CUB Global Desonerado (mensal)
4. PIB Brasil (trimestral)
5. PIB ConstruÃ§Ã£o Civil (trimestral)
6. Investimento ConstruÃ§Ã£o Civil (trimestral)
7. Investimento Infraestrutura (trimestral)
8. ParticipaÃ§Ã£o ConstruÃ§Ã£o no PIB (trimestral)
9. Consumo Cimento (mensal)
10. ProduÃ§Ã£o Cimento (mensal)
11. IPCA (mensal)
12. SELIC (diÃ¡rio)
13. Taxa Desemprego (mensal)

TOTAL: 13 fontes crÃ­ticas â†’ 13 novas abas Google Sheets

Autor: matheusoption-bit
Data: 2025-11-14
"""

import os
import sys
import time
import requests
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional

# Constantes
SPREADSHEET_ID = "11-KC18ShMKXZOSbWvHcLHJwz3oDjexGQLb26xm2Wq4w"
CREDENTIALS_PATH = "config/google_credentials.json"

# Fontes crÃ­ticas da Fase 1
FONTES_FASE1 = {
    "cub_global_oneroso": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_06.A.01_BI_54.xlsx",
        "aba_destino": "cub_on_global",
        "descricao": "CUB Global - SÃ©rie HistÃ³rica",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "tipo_cub", "valor_m2"],
        "cor_aba": {"red": 0.20, "green": 0.66, "blue": 0.33}
    },
    "cub_global_uf": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_06.A.06_BI_53.xlsx",
        "aba_destino": "cub_on_global_uf",
        "descricao": "CUB por UF - Global",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "uf", "tipo_cub", "valor_m2"],
        "cor_aba": {"red": 0.20, "green": 0.66, "blue": 0.33}
    },
    "cub_global_desonerado": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_06.B.01_BI_53.xlsx",
        "aba_destino": "cub_des_global",
        "descricao": "CUB Global Desonerado",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "tipo_cub", "valor_m2"],
        "cor_aba": {"red": 0.98, "green": 0.74, "blue": 0.02}
    },
    "pib_brasil": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_02.D.01_44.xlsx",
        "aba_destino": "pib_brasil_serie",
        "descricao": "PIB Brasil - SÃ©rie HistÃ³rica",
        "frequencia": "trimestral",
        "colunas_esperadas": ["data_referencia", "pib_valor", "variacao_trim", "variacao_anual"],
        "cor_aba": {"red": 0.92, "green": 0.26, "blue": 0.21}
    },
    "pib_construcao": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_02.D.02_44.xlsx",
        "aba_destino": "pib_construcao_civil",
        "descricao": "PIB ConstruÃ§Ã£o Civil",
        "frequencia": "trimestral",
        "colunas_esperadas": ["data_referencia", "pib_construcao", "variacao_trim", "variacao_anual"],
        "cor_aba": {"red": 0.92, "green": 0.26, "blue": 0.21}
    },
    "investimento_construcao": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_02.D.04_44.xlsx",
        "aba_destino": "inv_construcao_civil",
        "descricao": "Investimento em ConstruÃ§Ã£o Civil",
        "frequencia": "trimestral",
        "colunas_esperadas": ["data_referencia", "investimento_valor", "variacao_trim", "variacao_anual"],
        "cor_aba": {"red": 0.92, "green": 0.26, "blue": 0.21}
    },
    "investimento_infraestrutura": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_02.D.14_19.xlsx",
        "aba_destino": "inv_infraestrutura",
        "descricao": "Investimento em Infraestrutura",
        "frequencia": "trimestral",
        "colunas_esperadas": ["data_referencia", "investimento_infra", "variacao_trim", "variacao_anual"],
        "cor_aba": {"red": 0.92, "green": 0.26, "blue": 0.21}
    },
    "participacao_construcao_pib": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_02.D.10_44.xlsx",
        "aba_destino": "pib_part_construcao",
        "descricao": "ParticipaÃ§Ã£o da ConstruÃ§Ã£o no PIB",
        "frequencia": "trimestral",
        "colunas_esperadas": ["data_referencia", "participacao_percentual", "valor_absoluto"],
        "cor_aba": {"red": 0.92, "green": 0.26, "blue": 0.21}
    },
    "consumo_cimento": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_07.A.03_Consumo_cimento_54.xlsx",
        "aba_destino": "mat_cimento_consumo",
        "descricao": "Consumo de Cimento",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "consumo_toneladas", "variacao_mensal", "variacao_anual"],
        "cor_aba": {"red": 0.61, "green": 0.61, "blue": 0.61}
    },
    "producao_cimento": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_07.A.04_Produ%C3%A7ao_cimento_53.xlsx",
        "aba_destino": "mat_cimento_producao",
        "descricao": "ProduÃ§Ã£o de Cimento",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "producao_toneladas", "variacao_mensal", "variacao_anual"],
        "cor_aba": {"red": 0.61, "green": 0.61, "blue": 0.61}
    },
    "ipca": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_09.B.02_n_70.xlsx",
        "aba_destino": "ind_ipca_consumidor",
        "descricao": "Ãndice de PreÃ§os Consumidor (IPCA)",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "ipca_valor", "variacao_mensal", "variacao_anual"],
        "cor_aba": {"red": 0.15, "green": 0.68, "blue": 0.68}
    },
    "selic": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_09.B.04_n_67.xlsx",
        "aba_destino": "ind_taxa_selic",
        "descricao": "Taxa de Juros (SELIC)",
        "frequencia": "diario",
        "colunas_esperadas": ["data_referencia", "taxa_selic", "variacao_diaria"],
        "cor_aba": {"red": 0.15, "green": 0.68, "blue": 0.68}
    },
    "desemprego": {
        "url": "http://www.cbicdados.com.br/media/anexos/tabela_09.B.06_n_595.xls",
        "aba_destino": "ind_taxa_desemprego",
        "descricao": "Taxa de Desemprego",
        "frequencia": "mensal",
        "colunas_esperadas": ["data_referencia", "taxa_desemprego", "variacao_mensal"],
        "cor_aba": {"red": 0.15, "green": 0.68, "blue": 0.68}
    }
}

class CBICETLProcessor:
    """Processador ETL para dados CBIC."""
    
    def __init__(self):
        self.setup_sheets_client()
        self.successful_extractions = 0
        self.failed_extractions = 0
        
    def setup_sheets_client(self):
        """Configura cliente Google Sheets."""
        print("ğŸ”— Configurando cliente Google Sheets...")
        
        scope = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        
        creds = Credentials.from_service_account_file(CREDENTIALS_PATH, scopes=scope)
        self.sheets_client = gspread.authorize(creds)
        self.spreadsheet = self.sheets_client.open_by_key(SPREADSHEET_ID)
        
        print("âœ… Cliente Google Sheets configurado")
    
    def extract_data_from_url(self, url: str, fonte_key: str) -> Optional[pd.DataFrame]:
        """
        Extrai dados de uma URL CBIC.
        
        Args:
            url: URL do arquivo Excel/CSV
            fonte_key: Chave identificadora da fonte
            
        Returns:
            DataFrame com dados extraÃ­dos ou None se falha
        """
        print(f"ğŸ“¥ Extraindo dados: {fonte_key}")
        print(f"   URL: {url}")
        
        try:
            # Determina tipo de arquivo
            if url.endswith('.xlsx'):
                df = pd.read_excel(url)
            elif url.endswith('.xls'):
                df = pd.read_excel(url)
            elif url.endswith('.csv'):
                df = pd.read_csv(url)
            else:
                print(f"   âš ï¸ Tipo de arquivo nÃ£o suportado: {url}")
                return None
            
            print(f"   âœ… ExtraÃ­dos: {len(df)} registros, {len(df.columns)} colunas")
            return df
            
        except Exception as e:
            print(f"   âŒ Erro na extraÃ§Ã£o: {str(e)}")
            return None
    
    def transform_data(self, df: pd.DataFrame, fonte_key: str, fonte_info: Dict) -> pd.DataFrame:
        """
        Transforma dados para formato padronizado.
        
        Args:
            df: DataFrame original
            fonte_key: Chave da fonte
            fonte_info: InformaÃ§Ãµes da fonte
            
        Returns:
            DataFrame transformado
        """
        print(f"ğŸ”„ Transformando dados: {fonte_key}")
        
        if df is None or df.empty:
            return df
        
        # Cria cÃ³pia para transformaÃ§Ã£o
        df_transformed = df.copy()
        
        # Adiciona metadados
        df_transformed['fonte_cbic'] = fonte_key
        df_transformed['descricao_fonte'] = fonte_info['descricao']
        df_transformed['frequencia'] = fonte_info['frequencia']
        df_transformed['data_extracao'] = datetime.now()
        df_transformed['versao_pipeline'] = "1.0.0"
        
        # Padroniza nomes de colunas (remove espaÃ§os, caracteres especiais)
        df_transformed.columns = [
            col.lower().replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '')
            for col in df_transformed.columns
        ]
        
        # Tenta identificar coluna de data
        date_columns = [col for col in df_transformed.columns if 
                       'data' in col or 'date' in col or 'mes' in col or 'ano' in col]
        
        if date_columns:
            try:
                df_transformed[date_columns[0]] = pd.to_datetime(df_transformed[date_columns[0]], errors='coerce')
                print(f"   ğŸ“… Coluna de data processada: {date_columns[0]}")
            except:
                print(f"   âš ï¸ Erro ao processar data: {date_columns[0]}")
        
        print(f"   âœ… Dados transformados: {len(df_transformed)} registros")
        return df_transformed
    
    def load_to_sheets(self, df: pd.DataFrame, aba_name: str, cor_aba: Dict) -> bool:
        """
        Carrega dados no Google Sheets.
        
        Args:
            df: DataFrame para carregar
            aba_name: Nome da aba de destino
            cor_aba: Cor da aba (RGB dict)
            
        Returns:
            True se sucesso, False caso contrÃ¡rio
        """
        print(f"ğŸ“¤ Carregando dados na aba: {aba_name}")
        
        if df is None or df.empty:
            print(f"   âš ï¸ DataFrame vazio - pulando")
            return False
        
        try:
            # Criar ou limpar aba
            try:
                worksheet = self.spreadsheet.worksheet(aba_name)
                worksheet.clear()
                print(f"   ğŸ”„ Aba '{aba_name}' limpa")
            except gspread.WorksheetNotFound:
                worksheet = self.spreadsheet.add_worksheet(
                    title=aba_name, 
                    rows=len(df) + 100, 
                    cols=len(df.columns) + 10
                )
                print(f"   â• Nova aba '{aba_name}' criada")
            
            # Preparar dados para upload
            headers = df.columns.tolist()
            values = [headers] + df.fillna('').astype(str).values.tolist()
            
            # Upload em lotes para evitar timeout
            batch_size = 100
            for i in range(0, len(values), batch_size):
                batch = values[i:i+batch_size]
                start_row = i + 1
                end_row = start_row + len(batch) - 1
                
                range_name = f"A{start_row}:Z{end_row}"
                worksheet.update(values=batch, range_name=range_name)
                
                print(f"   ğŸ“¦ Lote {i//batch_size + 1}: linhas {start_row}-{end_row}")
                time.sleep(1)  # Evitar rate limits
            
            # FormataÃ§Ã£o do header
            worksheet.format("A1:Z1", {
                "backgroundColor": cor_aba,
                "textFormat": {"foregroundColor": {"red": 1, "green": 1, "blue": 1}, "bold": True}
            })
            
            print(f"   âœ… Upload concluÃ­do: {len(df)} linhas em '{aba_name}'")
            return True
            
        except Exception as e:
            print(f"   âŒ Erro no upload: {str(e)}")
            return False
    
    def process_fonte(self, fonte_key: str, fonte_info: Dict) -> bool:
        """
        Processa uma fonte CBIC completa (ETL).
        
        Args:
            fonte_key: Chave da fonte
            fonte_info: DicionÃ¡rio com informaÃ§Ãµes da fonte
            
        Returns:
            True se processamento bem-sucedido
        """
        print(f"\n{'='*60}")
        print(f"ğŸš€ PROCESSANDO FONTE: {fonte_key.upper()}")
        print(f"ğŸ“‹ DescriÃ§Ã£o: {fonte_info['descricao']}")
        print(f"â±ï¸ FrequÃªncia: {fonte_info['frequencia']}")
        print(f"ğŸ¯ Aba destino: {fonte_info['aba_destino']}")
        print(f"{'='*60}")
        
        # Extract
        df = self.extract_data_from_url(fonte_info['url'], fonte_key)
        if df is None:
            self.failed_extractions += 1
            return False
        
        # Transform
        df_transformed = self.transform_data(df, fonte_key, fonte_info)
        if df_transformed is None:
            self.failed_extractions += 1
            return False
        
        # Load
        success = self.load_to_sheets(
            df_transformed, 
            fonte_info['aba_destino'], 
            fonte_info['cor_aba']
        )
        
        if success:
            self.successful_extractions += 1
            print(f"âœ… Fonte {fonte_key} processada com sucesso!")
        else:
            self.failed_extractions += 1
            print(f"âŒ Fonte {fonte_key} falhou no processamento!")
        
        return success
    
    def run_fase1_complete(self):
        """Executa processamento completo da Fase 1."""
        print("ğŸš€ INICIANDO FASE 1 - FONTES CRÃTICAS CBIC")
        print(f"ğŸ“… Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š Total de fontes: {len(FONTES_FASE1)}")
        
        start_time = datetime.now()
        
        # Processa cada fonte
        for fonte_key, fonte_info in FONTES_FASE1.items():
            try:
                self.process_fonte(fonte_key, fonte_info)
                time.sleep(2)  # Pausa entre fontes para evitar sobrecarga
            except KeyboardInterrupt:
                print("\nâ¹ï¸ Processamento interrompido pelo usuÃ¡rio")
                break
            except Exception as e:
                print(f"\nâŒ Erro inesperado na fonte {fonte_key}: {str(e)}")
                self.failed_extractions += 1
                continue
        
        # RelatÃ³rio final
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š RELATÃ“RIO FINAL - FASE 1")
        print(f"{'='*70}")
        print(f"â±ï¸ DuraÃ§Ã£o total: {duration}")
        print(f"âœ… Fontes processadas com sucesso: {self.successful_extractions}")
        print(f"âŒ Fontes com falha: {self.failed_extractions}")
        print(f"ğŸ“ˆ Taxa de sucesso: {self.successful_extractions/(self.successful_extractions + self.failed_extractions)*100:.1f}%")
        print(f"ğŸ”— Planilha: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}")
        
        if self.successful_extractions > 0:
            print(f"\nğŸ‰ FASE 1 CONCLUÃDA COM SUCESSO!")
            print(f"ğŸ“Š {self.successful_extractions} novas abas criadas no Google Sheets")
            print(f"ğŸš€ Sistema de BI CBIC expandido significativamente!")
        else:
            print(f"\nâŒ FASE 1 FALHOU - Nenhuma fonte processada com sucesso")
        
        print(f"{'='*70}\n")

def main():
    """FunÃ§Ã£o principal da Fase 1."""
    processor = CBICETLProcessor()
    processor.run_fase1_complete()

if __name__ == "__main__":
    main()