# Changelog - UPSERT Implementation

## [1.1.0] - 2025-11-10

### ğŸ¯ Objetivo
Eliminar duplicaÃ§Ã£o de dados na aba `fact_series` do Google Sheets implementando lÃ³gica UPSERT (Update or Insert).

### âœ¨ Novas Funcionalidades

#### 1. MÃ©todo `read_fact_series()`
- **Arquivo:** `src/etl/sheets.py`
- **Linha:** ~478
- **DescriÃ§Ã£o:** LÃª dados existentes da aba `fact_series` e retorna como DataFrame pandas
- **Funcionalidades:**
  - Leitura completa da aba com conversÃ£o automÃ¡tica de tipos
  - Retorna DataFrame vazio se aba nÃ£o existir (tratamento robusto)
  - ConversÃ£o de colunas numÃ©ricas (`valor`, `variacao_mom`, `variacao_yoy`)
  - Logging detalhado com contagem de linhas e colunas

#### 2. MÃ©todo `deduplicate_fact_series()`
- **Arquivo:** `src/etl/sheets.py`
- **Linha:** ~541
- **DescriÃ§Ã£o:** Remove duplicatas do DataFrame por `id_fato`
- **Funcionalidades:**
  - Identifica duplicatas usando `id_fato` como chave Ãºnica
  - MantÃ©m registro mais recente baseado em `created_at`
  - Retorna tupla `(DataFrame limpo, nÃºmero de duplicatas removidas)`
  - Logging de duplicatas encontradas e removidas

### ğŸ”„ ModificaÃ§Ãµes

#### MÃ©todo `write_fact_series()` - UPSERT Logic
- **Arquivo:** `src/etl/sheets.py`
- **Linha:** ~597
- **MudanÃ§a:** SubstituiÃ§Ã£o de `append_to_sheet()` por lÃ³gica UPSERT completa

**Fluxo implementado:**
1. **Preparar novos dados:** Adicionar `id_fato`, metadados, calcular variaÃ§Ãµes
2. **Ler dados existentes:** Usar `read_fact_series()` para obter registros atuais
3. **Identificar novos vs. atualizaÃ§Ãµes:** Comparar `id_fato` para detectar duplicatas
4. **Combinar dados:** Remover registros duplicados dos existentes, adicionar novos/atualizados
5. **Deduplicar:** Usar `deduplicate_fact_series()` para garantir unicidade
6. **Sobrescrever aba:** `worksheet.clear()` + `worksheet.update()` com dados limpos

**Logging detalhado:**
```python
logger.info(
    "fact_series_upsert_complete",
    series_id="ipca",
    exec_id="exec_20231101_120000",
    existing_rows=50,        # Linhas antes do UPSERT
    new_rows=3,              # Linhas realmente novas
    updated_rows=2,          # Linhas atualizadas
    final_total=53,          # Total final
    operation="upsert"
)
```

### ğŸ§ª Testes

#### Arquivo: `tests/test_sheets_upsert.py`
- **Total de testes:** 12
- **Status:** âœ… 12 passed
- **Coverage:** 50% em `src/etl/sheets.py`

**Classes de teste:**
1. `TestReadFactSeries` (3 testes)
   - Leitura com dados
   - Aba vazia
   - Aba nÃ£o encontrada

2. `TestDeduplicateFactSeries` (4 testes)
   - Com duplicatas
   - Sem duplicatas
   - DataFrame vazio
   - Sem coluna `id_fato`

3. `TestWriteFactSeriesUpsert` (4 testes)
   - Sem dados existentes
   - Com dados novos
   - Com duplicatas
   - ValidaÃ§Ã£o de colunas

4. `TestUpsertIntegration` (1 teste)
   - MÃºltiplas sÃ©ries

### ğŸ“š DocumentaÃ§Ã£o

#### Arquivo: `docs/UPSERT_IMPLEMENTATION.md`
- DocumentaÃ§Ã£o completa da implementaÃ§Ã£o
- Diagramas de fluxo
- Exemplos de uso
- MÃ©tricas de performance
- FAQ

### âš ï¸ Breaking Changes

**Comportamento modificado:**
- **Antes:** `write_fact_series()` sempre adicionava dados (append)
- **Depois:** `write_fact_series()` sobrescreve aba com dados dedupicados (UPSERT)

**Impacto:**
- âœ… **Positivo:** Elimina duplicaÃ§Ã£o de dados
- âœ… **Positivo:** Jobs idempotentes (podem rodar mÃºltiplas vezes)
- âš ï¸ **AtenÃ§Ã£o:** Aba Ã© sobrescrita completamente (comportamento esperado)

**Compatibilidade:**
- âœ… Assinatura do mÃ©todo permanece idÃªntica
- âœ… CÃ³digo existente continua funcionando
- âœ… Sem quebras de API

### ğŸ“Š Performance

| MÃ©trica | Antes | Depois | DiferenÃ§a |
|---------|-------|--------|-----------|
| **API Calls** | 1 (append) | 2 (read + update) | +1 call |
| **Duplicatas** | âŒ Sim | âœ… NÃ£o | Eliminadas |
| **Tempo execuÃ§Ã£o** | ~0.5s | ~1.0s | +0.5s |
| **IdempotÃªncia** | âŒ NÃ£o | âœ… Sim | Implementada |

**OtimizaÃ§Ãµes:**
- Usa pandas para operaÃ§Ãµes em memÃ³ria (rÃ¡pido)
- Batch update com `worksheet.update()` (1 chamada)
- MantÃ©m rate limiting existente

### ğŸ” ValidaÃ§Ã£o

**Como verificar:**
```bash
# 1. Executar job duas vezes
python -m src.jobs.daily_bcb
python -m src.jobs.daily_bcb  # Segunda execuÃ§Ã£o

# 2. Verificar logs
grep "fact_series_upsert_complete" logs/*.log

# 3. Verificar ausÃªncia de duplicatas
# No Google Sheets: count UNIQUE(id_fato) deve ser igual ao total de linhas
```

### ğŸš€ PrÃ³ximos Passos

- [ ] Executar testes em ambiente de staging
- [ ] Monitorar performance em produÃ§Ã£o
- [ ] Validar logs de UPSERT
- [ ] Confirmar eliminaÃ§Ã£o de duplicatas
- [ ] Documentar mÃ©tricas observadas

### ğŸ‘¥ Autor
- **ImplementaÃ§Ã£o:** GitHub Copilot
- **Data:** 2025-11-10
- **Issue:** DuplicaÃ§Ã£o de dados em `fact_series`

### ğŸ“ Notas TÃ©cnicas

**DecisÃµes de design:**
1. **Sobrescrever vs. Update seletivo:** Escolhido sobrescrever pela simplicidade e garantia de integridade
2. **Pandas para deduplicaÃ§Ã£o:** Eficiente para datasets tÃ­picos (< 100k registros)
3. **Logging detalhado:** Facilita debugging e monitoramento
4. **IdempotÃªncia:** Jobs podem rodar mÃºltiplas vezes sem efeitos colaterais

**LimitaÃ§Ãµes conhecidas:**
- Performance degrada com datasets muito grandes (> 100k registros)
- ConcorrÃªncia nÃ£o gerenciada (last-write-wins)
- Requer leitura completa da aba antes de escrever

**Melhorias futuras:**
- [ ] Implementar update incremental para datasets grandes
- [ ] Adicionar lock distribuÃ­do para concorrÃªncia
- [ ] Otimizar leitura com ranges especÃ­ficos
- [ ] Cache de dados existentes para reduzir API calls

---

## Compatibilidade

- **Python:** 3.13.7+
- **pandas:** 2.3.3+
- **gspread:** 6.1.0+
- **Google Sheets API:** v4

## Testado em

- âœ… Windows 11 (Python 3.13.7)
- âœ… Ambiente virtual (.venv)
- âœ… pytest 7.4.3

## ReferÃªncias

- [Google Sheets API Documentation](https://developers.google.com/sheets/api)
- [pandas.DataFrame.drop_duplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)
- [gspread Documentation](https://docs.gspread.org/)
